---
layout: post
title: Deep Learning for Vision Systems - 1
description: >
  Howdy! This is the summary note for "Deep Learning for Vision Systems"
#sitemap: false
hide_last_modified: true
categories: [Deep Learning]
---

# Chapter 2. 딥러닝과 신경망
# 2.1 퍼셉트론
신경망은 많은 수의 뉴런으로 이루어져 층 모양으로 배열되어 계산을 수행함. 이를 다층 퍼셉트론이라 칭한다. 해당 그래프 구조의 각 노드를 뉴런이라 부름.
## 2.1.1 퍼셉트론이란? 
퍼셉트론은 뉴런이 하나뿐인 가장 간단한 형태의 신경망임. 생물학적 뉴런에서는 여러개의 수상돌기로부터 다른 세기의 전기신호를 받음. 이들의 합이 임곗값을 넘으면 시냅스를 통해 출력신호를 보냄. 인공 뉴런 역시 두 가지 함수를 통해 이를 모형화함. 전체 입력 신호 세기의 합을 구하는 가중합(weighted sum)과 입력 세기의 합이 입계값을 넘으면 출력 신호를 보내는 스텝 함수(step function)이다. 모든 특징이 유용한 것은 아니기에 각 노드에는 해당 특징의 중요도가 부여되는데 이 값을 결합 가중치라 한다.

각 노드, 입력 특징(x1)은 해당 특징이 출력에 영향을 미치는 중요도를 나타내는 가중치(w1)를 부여받는다. 

- 입력 벡터 : X
- 가중치 벡터 : w
- 뉴런 함수: 입력 신호를 변환하는 계산 수행을 위한 가중합 함수와 스텝 활성화 함수가 사용된다.  
- 출력: 활성화 함수에 의해 결정된다. Z

가중합은 선형 결합(linera combination)이라고도 하며 각 가중치를 곱한 입력값의 합에 편향을 더한 값으로 정의된다. 

```
z = np.dot(w.T, X) + b
```

여기서 b는 y절편으로 편향을 의미함. 직선을 정의할 때는 두 정보가 필요함. 하나는 직선의 기울기랑, 다른 하나는 직선이 지나는 점이다. 편향은 직선이 지나는 y축에서의 점이다. 이를 조정하면 데이터에 대한 예측이 더욱 정확해진다. 입력층에 항상 값이 1인 입력 노드를 하나 추가하면 편향을 추가한 것과 같은 효과를 얻을 수 있다고 한다. 신경망의 학습과정에서 편향은 가중치가 하나 추가된것과 같이 취급되어 가중치와 마찬가지로 비용 함수값이 최소가 되도록 초기화된다. 

활성화 함수는 입력 신호의 가중합을 입력 받아 이 가중합이 미러 정해진 임계값보다 크면 뉴런을 활성화시킨다. 퍼셉트론에서의 활성화함수는 0,1만 출력하는 스텝 함수이다. 

```
def step_function(z):
  if z <= 0:
    return 0
  else:
    return 1
```

## 2.1.2 퍼셉트론은 어떻게 학습을 할까?
1. 뉴런이 입력의 가중합을 계산하여 활성화 함수에 입력하여 예측값을 정함. 이 과정은 순방향 계산이라 한다.
2. 예측값과 실제 레이블 값을 비교해서 오차를 계산한다.
3. 오차에 따라 가중치를 조정한다. 예측값이 너무 높으면 다시 낮아지게, 너무 낮으면 높아지게.
4. 이 과정을 반복한다. 

## 2.1.3 하나의 뉴런으로도 복잡한 문제를 해결할 수 있을까
불가능하다. 퍼셉트론은 선형함수이다. 이는 뉴런이 데이터를 나누는 경계가 직선이란 뜻임. 퍼셉트론은 데이터를 잘 분리(최적합)하는 직선을 정의하는 가장 좋은 가중치와 편향을 갖게 될 것이다. 선형 분리 가능한 데이터이면 가능하지만 비선형 데이터셋의 경우 데이터에 적합하지 않게 된다. 더 복잡한 신경망을 필요로 함. 2개의 퍼셉트론을 갖는 신경망이라면? 2개의 퍼셉트론은 2개의 직선으로 조금은 더 나은 결과를 보일것이다. 

뉴런을 많이 추가할 수록 더 적합한 경계를 얻을 수 있을 것 같아 보임. 그런데 오히려 너무 많아지면 학습 데이터셋에만 최적화되는 overfitting 과적합 현상이 발생함. 

# 2.2 다층 퍼셉트론
## 2.2.1 다층 퍼셉트론의 구조
신경망을 구성하는 주요 구성요소는 다음과 같다. 
- 입력층: 특징 벡터들이 담기는 곳
- 은닉층: 층 모양으로 쌓은 뉴런으로 구성된다. 입력층과 출력층 사이에서 학습되는 동안 입력을 제어하거나 출력을 볼수 없어서 은닉층이라 불린다.
- 결합 가중치: 출력에 해당되는 입력의 영향력을 나타내는 가중치. 노드를 연결하는 그래프의 에지에 해당됨.
- 출력층: 모델의 예측 결과가 출력되는 층. 

## 2.2.2 은닉층이란
실제 특징이 학습되는 곳이다. 

## 2.2.3 층수와 층을 이루는 노드 수
신경망 설계와 하이퍼 파라미터를 튜닝할때는 그저 직관대로 할 뿐. 설계시 중요한 점은 층수와 층을 이루는 노드 수이다. 신경망은 